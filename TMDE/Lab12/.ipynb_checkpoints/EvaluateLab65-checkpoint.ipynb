{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Lab Evaluator\n",
    "\n",
    "## Assessment based on student-provided results\n",
    "\n",
    "Version History:\n",
    "\n",
    "Version 0.1 - Jerónimo Arenas García, Jesús Cid Sueiro, Vanessa Gómez Verdejo, Dec. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import scipy.io as sio\n",
    "import scipy\n",
    "import zipfile as zp\n",
    "import shutil\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read datafiles for all students\n",
    "\n",
    "Student datafiles can be in any of the following formats:\n",
    "\n",
    "   * `'.zip'`: When uncompressed, the zip may contain one or several matlab files. All matlab files are read and incorporated to a pandas Dataframe where each student is a column, and each index is a variable available for the exam solution\n",
    "   * `.mat'`: All data variables for the students are given in a single matlab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readdatafiles(datafiles_path, splitsymbol):\n",
    "\n",
    "    temporary_dir = './tmp'\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    datafiles = [f for f in os.listdir(datafiles_path) if isfile(join(datafiles_path, f))]\n",
    "    for dtfile in datafiles:\n",
    "        if dtfile.endswith('zip'):\n",
    "            #All files will be extracted and the contents incorporated to the Dataframe\n",
    "            NIA = dtfile.split(splitsymbol)[0]\n",
    "            idx = []\n",
    "            val = []\n",
    "            zpobj = zp.ZipFile(join(datafiles_path, dtfile))\n",
    "            for fileinzip in zpobj.namelist():\n",
    "                if fileinzip.endswith('mat'):\n",
    "                    #Matlab files are extracted to a temporal subfolder\n",
    "                    zpobj.extract(fileinzip, temporary_dir)\n",
    "                    data = sio.loadmat(join(temporary_dir,fileinzip))\n",
    "                    #Read all variable names and the corresponding data values\n",
    "                    for var in [el for el in data.keys() if not el.startswith('_')]:\n",
    "                        idx.append(var)\n",
    "                        val.append(data[var])\n",
    "            #If\n",
    "            if idx:\n",
    "                df[NIA] = pd.Series(val,index=idx)\n",
    "                \n",
    "            #Remove temporary directory, if it has been created\n",
    "            if os.path.exists(temporary_dir):\n",
    "                shutil.rmtree(temporary_dir)\n",
    "                    \n",
    "        elif dtfile.endswith('mat'):\n",
    "            NIA = dtfile.split(splitsymbol)[0]\n",
    "                \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in dataframe: 13\n",
      "Number of variables read: 6\n",
      "Displaying data for first three students ... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100303808</th>\n",
       "      <th>100304681</th>\n",
       "      <th>100304949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xTest</th>\n",
       "      <td>[[0.631282448926, 1.64150758814, 2.09987119644...</td>\n",
       "      <td>[[-1.89718639589, -1.74203604586, 4.4573635199...</td>\n",
       "      <td>[[2.40317872945, 1.40489089702, -2.13516524453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sTrain</th>\n",
       "      <td>[[-0.864436977117], [1.99703014836], [1.927627...</td>\n",
       "      <td>[[-1.5137234212], [0.239133213339], [0.3368213...</td>\n",
       "      <td>[[1.25352724407], [0.362781352027], [2.4699063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xTrain</th>\n",
       "      <td>[[-1.78058792839, 2.15171751992, -0.1602248336...</td>\n",
       "      <td>[[-3.36505903707, -4.3997978412, 1.21246472357...</td>\n",
       "      <td>[[-2.31544356008, 5.09767849663, -3.3679701578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ytrain</th>\n",
       "      <td>[[0], [0], [1], [0], [0], [0], [1], [0], [1], ...</td>\n",
       "      <td>[[1], [0], [1], [0], [0], [1], [1], [0], [1], ...</td>\n",
       "      <td>[[0], [0], [1], [1], [0], [0], [0], [0], [1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xtest</th>\n",
       "      <td>[[0.861005153264, -0.33199281318, -0.634148786...</td>\n",
       "      <td>[[1.54746676587, 2.23404086186, 2.02277621279,...</td>\n",
       "      <td>[[0.487141581144, -1.10807880271, -0.273434394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xtrain</th>\n",
       "      <td>[[-1.12224865846, 1.47888751529, -0.6233066600...</td>\n",
       "      <td>[[3.24059249073, 0.938560898107, 1.21274526402...</td>\n",
       "      <td>[[-0.331821077768, -0.124303015512, 0.04471270...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                100303808  \\\n",
       "xTest   [[0.631282448926, 1.64150758814, 2.09987119644...   \n",
       "sTrain  [[-0.864436977117], [1.99703014836], [1.927627...   \n",
       "xTrain  [[-1.78058792839, 2.15171751992, -0.1602248336...   \n",
       "ytrain  [[0], [0], [1], [0], [0], [0], [1], [0], [1], ...   \n",
       "Xtest   [[0.861005153264, -0.33199281318, -0.634148786...   \n",
       "Xtrain  [[-1.12224865846, 1.47888751529, -0.6233066600...   \n",
       "\n",
       "                                                100304681  \\\n",
       "xTest   [[-1.89718639589, -1.74203604586, 4.4573635199...   \n",
       "sTrain  [[-1.5137234212], [0.239133213339], [0.3368213...   \n",
       "xTrain  [[-3.36505903707, -4.3997978412, 1.21246472357...   \n",
       "ytrain  [[1], [0], [1], [0], [0], [1], [1], [0], [1], ...   \n",
       "Xtest   [[1.54746676587, 2.23404086186, 2.02277621279,...   \n",
       "Xtrain  [[3.24059249073, 0.938560898107, 1.21274526402...   \n",
       "\n",
       "                                                100304949  \n",
       "xTest   [[2.40317872945, 1.40489089702, -2.13516524453...  \n",
       "sTrain  [[1.25352724407], [0.362781352027], [2.4699063...  \n",
       "xTrain  [[-2.31544356008, 5.09767849663, -3.3679701578...  \n",
       "ytrain  [[0], [0], [1], [1], [0], [0], [0], [0], [1], ...  \n",
       "Xtest   [[0.487141581144, -1.10807880271, -0.273434394...  \n",
       "Xtrain  [[-0.331821077768, -0.124303015512, 0.04471270...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "datafiles_path = './datafiles_Gbil/'\n",
    "##########################################\n",
    "\n",
    "student_data = readdatafiles(datafiles_path, splitsymbol='.')\n",
    "\n",
    "print 'Number of students in dataframe: ' + str(student_data.shape[1])\n",
    "print 'Number of variables read: ' + str(student_data.shape[0])\n",
    "\n",
    "print 'Displaying data for first three students ... '\n",
    "student_data[student_data.columns[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read answers provided by students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Read student results into panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "results_path = './entregas_Gbil/'\n",
    "#Requested variable names in the wording of the exam\n",
    "truenames = ['vTrain', 'xnTrain', 'xnTest', 'we', 'w', 'EAP', 'm0', 'etaNPx1', 'PDx1', 'tm', 'tv', 'ytest']\n",
    "###########################################\n",
    "\n",
    "student_results = readdatafiles(results_path, splitsymbol='_')\n",
    "newindex = truenames+[el for el in student_results.index.tolist() if el not in truenames]\n",
    "student_results = student_results.reindex(newindex)\n",
    "\n",
    "print 'Number of students in dataframe: ' + str(student_results.shape[1])\n",
    "print 'Number of variables read: ' + str(student_results.shape[0])\n",
    "\n",
    "print 'Displaying data for first three students ... '\n",
    "student_results[student_results.columns[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Common Mistakes on variable names\n",
    "\n",
    "In view of all variable names provided by all students, we may decide to allow alternative names for variables without any penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in dataframe: 7\n",
      "\n",
      "Displaying number of missing data per variable name. \n",
      "Those with a large number are a potential common mistakes\n",
      "for a variable name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vTrain     1\n",
       "xnTrain    0\n",
       "xnTest     0\n",
       "we         0\n",
       "w          3\n",
       "EAP        3\n",
       "m0         0\n",
       "etaNPx1    2\n",
       "PDx1       3\n",
       "tm         3\n",
       "tv         3\n",
       "ytest      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Number of students in dataframe: ' + str(student_results.shape[1])\n",
    "\n",
    "print '\\nDisplaying number of missing data per variable name. \\nThose with a large number are a potential common mistakes\\nfor a variable name'\n",
    "\n",
    "student_results.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "\n",
    "#Dictionary with accepted mistakes in the following format\n",
    "#  Expected variable name : Accepted mistake\n",
    "Mistakes = {};\n",
    "##########################################\n",
    "\n",
    "for el in Mistakes:\n",
    "    student_results.loc[el] = student_results.loc[el].fillna(student_results.loc[Mistakes[el]])\n",
    "    \n",
    "for el in student_results.index.tolist():\n",
    "    if el not in truenames:\n",
    "        student_results.drop(el, inplace=True)\n",
    "        \n",
    "student_results[student_results.columns[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Name to NIA dictionary\n",
    "\n",
    "Finally, since datafiles are created by NIA and results are available per student name, we need to create a dictionary connecting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "excel_file = 'lista_clase_65.xlsx'\n",
    "###########################################\n",
    "\n",
    "student_NIA_names = pd.read_excel(excel_file)\n",
    "\n",
    "#UTF-8 encoding of everything\n",
    "for fld in student_NIA_names.keys():\n",
    "    if fld != 'NIU':\n",
    "        student_NIA_names[fld] = student_NIA_names[fld].str.encode('utf8')\n",
    "\n",
    "NIA_name = {}\n",
    "\n",
    "for el in student_results.columns.tolist():\n",
    "\n",
    "    sim_list = []\n",
    "\n",
    "    for idx,NIA in enumerate(student_NIA_names['NIU'].values):\n",
    "    \n",
    "        std_name = student_NIA_names['First name'].values.tolist()[idx] + ' ' + \\\n",
    "                        student_NIA_names['Surname'].values.tolist()[idx]\n",
    "        sim_list.append(difflib.SequenceMatcher(a=el.lower(), b=std_name.lower()).ratio())\n",
    "    \n",
    "    max_sim = max(sim_list)\n",
    "    max_idx = sim_list.index(max_sim)\n",
    "    \n",
    "    NIA_name[student_NIA_names['NIU'].values.tolist()[max_idx]] = el\n",
    "    \n",
    "#Create name to NIA dictionary\n",
    "name_NIA = {NIA_name[el]: el for el in NIA_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print name_NIA\n",
    "#print NIA_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have:\n",
    "\n",
    "   * student_data: dataframe with data given to the students. Each index is a variable, and each column a NIA\n",
    "   * student_results: dataframe with student results. Each index is a variable, and each column a name\n",
    "   * NIA_name: NIA to name dictionary\n",
    "   * name_NIA: name to NIA dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Exam solution\n",
    "\n",
    "In this section we implement the solution to the exam. This is a function that takes the variables generated for a given student and the answers provided by the student, and generates a structure with all posible answers, possibly with a penalty term associated to each answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print NIA_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print student_data[N]\n",
    "#print student_results['OLGA HERRANZ MACIAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SolveLabXX(data, st_solution):\n",
    "    \"\"\"Solver for the practical\n",
    "    Input parameters:\n",
    "    data: A series with the data given to the student\n",
    "    st_solution: The solution provided by the student\n",
    "    \n",
    "    Output: A dataseries where each element is a list of tuples\n",
    "    with the format [(solution1, factor1), (solution2, factor2)]\n",
    "    \n",
    "    Factors are multiplicative factors to account for possible\n",
    "    penalties. A factor 1 should be given to a solution that should\n",
    "    not be penalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    ds_values = []\n",
    "    ds_indexes = []\n",
    "    \n",
    "    ## Sec. 2.1\n",
    "    vTrain = []\n",
    "    vTrain.append((np.var(data['xTrain'], axis=0, ddof=0), 1))\n",
    "    vTrain.append((np.var(data['xTrain'], axis=0, ddof=1), 1))\n",
    "    \n",
    "    ds_values.append(vTrain)\n",
    "    ds_indexes.append('vTrain')\n",
    "    \n",
    "    ## Sec. 2.2\n",
    "    xnTrain = []\n",
    "    xnTest = []\n",
    "    \n",
    "    mean = np.mean(data['xTrain'], axis=0)\n",
    "    xnTrain.append(((data['xTrain'] - mean) / np.sqrt(vTrain[0][0]), 1))\n",
    "    xnTrain.append(((data['xTrain'] - mean) / np.sqrt(vTrain[1][0]), 1))\n",
    "    \n",
    "    xnTest.append(((data['xTest'] - mean) / np.sqrt(vTrain[0][0]), 1))\n",
    "    xnTest.append(((data['xTest'] - mean) / np.sqrt(vTrain[1][0]), 1))\n",
    "    \n",
    "    ds_values.append(xnTrain)\n",
    "    ds_values.append(xnTest)\n",
    "    ds_indexes.append('xnTrain')\n",
    "    ds_indexes.append('xnTest')\n",
    "    \n",
    "    ## Sec. 2.3 Damos por buenas tres posibilidades, las que se obtienen con cualquiera\n",
    "    # de las versiones normalizadas de los datos de entrada, o la que se obtiene con\n",
    "    # la matriz de datos de entrada utilizada por el estudiante (su campo xnTrain)\n",
    "    #\n",
    "    # La version sin sesgo se acepta con una penalización del 50%\n",
    "    we = []\n",
    "    ntr = data['xTrain'].shape[0]\n",
    "    xnTraine = np.hstack((np.ones((ntr,1)),xnTrain[0][0]))\n",
    "    we.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "    xnTraine = np.hstack((np.ones((ntr,1)),xnTrain[1][0]))\n",
    "    we.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "    # Use own data if not nan, and has the right dimensions\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            xnTraine = np.hstack((np.ones((ntr,1)),st_solution['xnTrain']))\n",
    "            we.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "            \n",
    "    # Versions with 50% penalty\n",
    "    we.append((np.linalg.lstsq(xnTrain[0][0], data['sTrain'])[0], .5))\n",
    "    we.append((np.linalg.lstsq(xnTrain[1][0], data['sTrain'])[0], .5))\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            we.append((np.linalg.lstsq(st_solution['xnTrain'], data['sTrain'])[0], .5))\n",
    "            \n",
    "    ds_values.append(we)\n",
    "    ds_indexes.append('we')\n",
    "    \n",
    "    #2.4\n",
    "    w = []\n",
    "    xnTraine = np.hstack((np.ones((ntr,1)),xnTrain[0][0]**[1, 2, 3, 4, 5]))\n",
    "    w.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "    xnTraine = np.hstack((np.ones((ntr,1)),xnTrain[1][0]**[1, 2, 3, 4, 5]))\n",
    "    w.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "    # Use own data if not nan, and has the right dimensions\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            xnTraine = np.hstack((np.ones((ntr,1)),st_solution['xnTrain']**[1, 2, 3, 4, 5]))\n",
    "            w.append((np.linalg.lstsq(xnTraine, data['sTrain'])[0], 1))\n",
    "            \n",
    "    # Versions with 50% penalty\n",
    "    w.append((np.linalg.lstsq(xnTrain[0][0]**[1, 2, 3, 4, 5], data['sTrain'])[0], .5))\n",
    "    w.append((np.linalg.lstsq(xnTrain[1][0]**[1, 2, 3, 4, 5], data['sTrain'])[0], .5))\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            w.append((np.linalg.lstsq(st_solution['xnTrain']**[1, 2, 3, 4, 5], data['sTrain'])[0], .5))\n",
    "\n",
    "    ds_values.append(w)\n",
    "    ds_indexes.append('w')\n",
    "\n",
    "    #2.5. Solution for this section is based on student solution.\n",
    "    EAP = []\n",
    "    # EAP for model of Section 2.3\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            xnTraine = np.hstack((np.ones((ntr,1)),st_solution['xnTrain']))\n",
    "            EAP.append((np.mean(np.abs(xnTraine.dot(we[2][0]) - data['sTrain'])), 1))\n",
    "            #If the sum instead of the average is calculated: x0.7\n",
    "            EAP.append((np.sum(np.abs(xnTraine.dot(we[2][0]) - data['sTrain'])), .7))\n",
    "    \n",
    "    # EAP for model of Section 2.4\n",
    "    if not np.all(np.isnan(st_solution['xnTrain'])):\n",
    "        if np.array_equal(st_solution['xnTrain'].shape, xnTrain[0][0].shape):\n",
    "            xnTraine = np.hstack((np.ones((ntr,1)),st_solution['xnTrain']**[1, 2, 3, 4, 5]))\n",
    "            EAP.append((np.mean(np.abs(xnTraine.dot(w[2][0]) - data['sTrain'])), 1))\n",
    "            #If the sum instead of the average is calculated: x0.7\n",
    "            EAP.append((np.sum(np.abs(xnTraine.dot(w[2][0]) - data['sTrain'])), .7))\n",
    "    \n",
    "    ds_values.append(EAP)\n",
    "    ds_indexes.append('EAP')\n",
    "    \n",
    "    #3.1. \n",
    "    m0 = []\n",
    "    \n",
    "    ind0 = np.where(data['ytrain']==0)[0]\n",
    "    ind1 = np.where(data['ytrain']==1)[0]\n",
    "    m0.append((np.mean(data['Xtrain'][ind0,]),1))\n",
    "    #50% penalty for those using only the first column\n",
    "    m0.append((np.mean(data['Xtrain'][ind0,0]),.5))\n",
    "    ds_values.append(m0)\n",
    "    ds_indexes.append('m0')\n",
    "    \n",
    "    #3.2.\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    etaNPx1 = []\n",
    "    etaNPx1.append((m0[0][0] + norm.ppf(0.9) * (2**.5), 1))\n",
    "    #We admit also the value computed using the m0 provided by the student\n",
    "    if not np.all(np.isnan(st_solution['m0'])):\n",
    "        if np.array_equal(st_solution['m0'][0].flatten().shape, m0[0][0].flatten().shape):\n",
    "            etaNPx1.append((st_solution['m0'][0] + norm.ppf(0.9) * (2**.5), 1))\n",
    "\n",
    "    ds_values.append(etaNPx1)\n",
    "    ds_indexes.append('etaNPx1')\n",
    "    \n",
    "    #3.3.\n",
    "\n",
    "    qfunc = lambda x: 0.5-0.5*scipy.special.erf(x/np.sqrt(2))\n",
    "    PDx1 = []\n",
    "    m1a = np.mean(data['Xtrain'][ind1,])\n",
    "    m1b = np.mean(data['Xtrain'][ind1,0])\n",
    "    \n",
    "    PDx1.append((qfunc((etaNPx1[0][0]-m1a)/(2**.5)), 1))\n",
    "    #We use the threshold provided by the student and the average of m1, using either \n",
    "    # all the data, or just the first column\n",
    "    if not np.all(np.isnan(st_solution['etaNPx1'])):\n",
    "        if np.array_equal(st_solution['etaNPx1'].flatten().shape, (1,)):\n",
    "            PDx1.append((qfunc((st_solution['etaNPx1'][0]-m1a)/(2**.5)), 1))\n",
    "            PDx1.append((qfunc((st_solution['etaNPx1'][0]-m1b)/(2**.5)), 1))\n",
    "    \n",
    "    ds_values.append(PDx1)\n",
    "    ds_indexes.append('PDx1')\n",
    "    \n",
    "    #3.4\n",
    "    tm = []\n",
    "    tv = []\n",
    "    \n",
    "    #Theoretical results\n",
    "    ndim = data['Xtrain'].shape[1]\n",
    "    tm.append(((1+np.arange(ndim)) * np.mean(data['Xtrain'][ind1,]), 1))\n",
    "    tv.append(((1+np.arange(ndim)) * 2, 1))\n",
    "    \n",
    "    #Results computed from data\n",
    "    tm.append((np.array([np.mean(np.sum(data['Xtrain'][ind1,:nvars+1], axis=1)) for nvars in range(ndim)]),1))\n",
    "    tv.append((np.array([np.var(np.sum(data['Xtrain'][ind1,:nvars+1], axis=1), ddof=0) for nvars in range(ndim)]),1))\n",
    "    tv.append((np.array([np.var(np.sum(data['Xtrain'][ind1,:nvars+1], axis=1), ddof=1) for nvars in range(ndim)]),1))\n",
    "        \n",
    "    ds_values.append(tm)\n",
    "    ds_indexes.append('tm')\n",
    "    ds_values.append(tv)\n",
    "    ds_indexes.append('tv')\n",
    "    \n",
    "    #3.5\n",
    "    ytest = []\n",
    "    tm0 = 3 * np.mean(data['Xtrain'][ind0,])\n",
    "    th = ((tm[0][0][2] + tm0)/2)\n",
    "    ytest.append(((np.sum(data['Xtrain'][:,:3], axis=1)>th).astype('int'),1))\n",
    "    \n",
    "    tm0 = np.mean(np.sum(data['Xtrain'][ind0,:3], axis=1))\n",
    "    th = ((tm[1][0][2] + tm0)/2)\n",
    "    ytest.append(((np.sum(data['Xtrain'][:,:3], axis=1)>th).astype('int'),1))\n",
    "    \n",
    "    ds_values.append(ytest)\n",
    "    ds_indexes.append('ytest')\n",
    "    \n",
    "    return pd.Series(ds_values, ds_indexes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of all students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def automatic_evaluator(student_results, solution, weights, tolerance):\n",
    "    if len(solution.keys())==len(weights) and len(solution.keys())==len(tolerance):\n",
    "        val = []\n",
    "        idx = []\n",
    "        for wgh,el,tol in zip(weights,solution.keys(),tolerance):\n",
    "            var_summary = []\n",
    "            #If the student has delivered the variable, append 1; otherwise 0\n",
    "            if not np.all(np.isnan(student_results[el])):\n",
    "                var_summary.append(1)\n",
    "                #Check all possible solutions against the one provided by the student\n",
    "                factors = [entry[1] for entry in solution[el]\n",
    "                       if np.array_equal(student_results[el].flatten().shape, entry[0].flatten().shape)\n",
    "                       and np.mean(np.abs(entry[0].flatten()-student_results[el].flatten()))<tol]\n",
    "                \n",
    "                if len(factors):\n",
    "                    max_factor = max(factors)\n",
    "                    var_summary.extend([1, max_factor, wgh, max_factor*wgh])\n",
    "                else:\n",
    "                    var_summary.extend([0, 0, wgh, 0])\n",
    "            else:\n",
    "                var_summary.extend([0, 0, 0, wgh, 0])\n",
    "            #Keep values corresponding to current variable\n",
    "            val.append(var_summary)\n",
    "            idx.append(el)\n",
    "        final_score = sum([item[-1] for item in val])\n",
    "        val.append(final_score)\n",
    "        idx.append('FinalScore')\n",
    "        return pd.Series(val,index=idx)\n",
    "    else:\n",
    "        print 'The number of weights and variables to evaluate differ. Please, check'\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "excel_output = 'Notas_65_Lab12.xlsx'\n",
    "weights = [1, .5, .5, 1, 1, 1, 1, 1, 1, .5, .5, 1]\n",
    "tolerance = [1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2]\n",
    "###########################################\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for NIA in NIA_name.keys():\n",
    "    solution = SolveLabXX(student_data[str(NIA)], student_results[NIA_name[NIA]])\n",
    "    df[NIA_name[NIA].decode('utf8')] = automatic_evaluator(student_results[NIA_name[NIA]], solution, weights, tolerance)\n",
    "\n",
    "df.T.to_excel(excel_output,columns=df.T.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Lab Evaluator\n",
    "\n",
    "## Assessment based on student-provided results\n",
    "\n",
    "Version History:\n",
    "\n",
    "Version 0.1 - Jerónimo Arenas García, Jesús Cid Sueiro, Vanessa Gómez Verdejo, Dec. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "import scipy.io as sio\n",
    "import scipy\n",
    "import zipfile as zp\n",
    "import shutil\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read datafiles for all students\n",
    "\n",
    "Student datafiles can be in any of the following formats:\n",
    "\n",
    "   * `'.zip'`: When uncompressed, the zip may contain one or several matlab/numpy files. All matlab/numpy files are read and incorporated to a pandas Dataframe where each student is a column, and each index is a variable available for the exam solution\n",
    "   * `.mat'`: All data variables for the students are given in a single matlab file\n",
    "   * `.npz'`: All data variables for the students are given in a single numpyº file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readdatafiles(datafiles_path, splitsymbol):\n",
    "\n",
    "    temporary_dir = './tmp'\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    datafiles = [f for f in os.listdir(datafiles_path) if isfile(join(datafiles_path, f))]\n",
    "    for dtfile in datafiles:\n",
    "        if dtfile.endswith('zip'):\n",
    "            #All files will be extracted and the contents incorporated to the Dataframe\n",
    "            NIA = dtfile.split(splitsymbol)[0]\n",
    "            #print NIA\n",
    "            idx = []\n",
    "            val = []\n",
    "            zpobj = zp.ZipFile(join(datafiles_path, dtfile))\n",
    "            for fileinzip in zpobj.namelist():\n",
    "                #Remove files beginning with '_' that may be hidden OS files \n",
    "                if (not fileinzip.startswith('_')) and (fileinzip.endswith('mat') or fileinzip.endswith('npz')):\n",
    "                    #Matlab/NPZ files are extracted to a temporal subfolder\n",
    "                    zpobj.extract(fileinzip, temporary_dir)\n",
    "                    if fileinzip.endswith('mat'):\n",
    "                        data = sio.loadmat(join(temporary_dir,fileinzip))\n",
    "                    else:\n",
    "                        data = np.load(join(temporary_dir,fileinzip))\n",
    "                        if data.keys()==['arr_0']:\n",
    "                            data = data['arr_0'].tolist()\n",
    "                    #Read all variable names and the corresponding data values\n",
    "                    for var in [el for el in data.keys() if not el.startswith('_')]:\n",
    "                        idx.append(var)\n",
    "                        val.append(data[var])\n",
    "            #If\n",
    "            if idx:\n",
    "                #print idx\n",
    "                #df = [df, pd.Series(val,index=idx, name=NIA)]\n",
    "                df = pd.concat([df, pd.Series(val,index=idx, name=NIA)], axis=1)\n",
    "                #df[NIA] = pd.Series(val,index=idx)\n",
    "                #print pd.Series(val,index=idx)\n",
    "                #print df[NIA]\n",
    "                \n",
    "            #Remove temporary directory, if it has been created\n",
    "            if os.path.exists(temporary_dir):\n",
    "                shutil.rmtree(temporary_dir)\n",
    "                    \n",
    "        elif dtfile.endswith('mat') or dtfile.endswith('npz'):\n",
    "            NIA = dtfile.split(splitsymbol)[0]\n",
    "            #print NIA\n",
    "            idx = []\n",
    "            val = []\n",
    "            if dtfile.endswith('mat'):\n",
    "                data = sio.loadmat(join(datafiles_path, dtfile))\n",
    "            else:\n",
    "                data = np.load(join(datafiles_path, dtfile))\n",
    "            #Read all variable names and the corresponding data values\n",
    "            for var in [el for el in data.keys() if not el.startswith('_')]:\n",
    "                idx.append(var)\n",
    "                val.append(data[var])\n",
    "                \n",
    "            if idx:\n",
    "                df = pd.concat([df, pd.Series(val,index=idx, name=NIA)], axis=1)\n",
    "                        \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in dataframe: 66\n",
      "Number of variables read: 9\n",
      "Displaying data for first three students ... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100276687</th>\n",
       "      <th>100284423</th>\n",
       "      <th>100290949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_knn</th>\n",
       "      <td>[[5]]</td>\n",
       "      <td>[[6]]</td>\n",
       "      <td>[[7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_reg</th>\n",
       "      <td>[[-1.81730391168], [-1.31959494449], [-3.12276...</td>\n",
       "      <td>[[-1.95300967366], [-0.219953516073], [0.77476...</td>\n",
       "      <td>[[-6.78524715177], [-0.167566954327], [-0.5772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sval_reg</th>\n",
       "      <td>[[0.469566566998], [0.434864239432], [-0.20126...</td>\n",
       "      <td>[[-1.69798029129], [-0.998549158711], [-7.1524...</td>\n",
       "      <td>[[5.21761697592], [1.21333038463], [-2.5538643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xtr_reg</th>\n",
       "      <td>[[0.871257484747, -0.820094192472], [-0.644532...</td>\n",
       "      <td>[[0.306152918607, 0.399930040105], [0.38405830...</td>\n",
       "      <td>[[-1.33671463676, -2.14137382412], [0.24677755...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xtr_rl</th>\n",
       "      <td>[[0.140463102615, 0.247669377199, -0.041431362...</td>\n",
       "      <td>[[-0.147325230568, 0.954388079256, -0.27748399...</td>\n",
       "      <td>[[0.524746496819, 0.296185529951, 0.7269493561...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xval_reg</th>\n",
       "      <td>[[-0.0087916089067, -2.38238053595], [-0.42707...</td>\n",
       "      <td>[[1.18442826324, -0.100688112884], [1.07725826...</td>\n",
       "      <td>[[-0.046398183217, 1.46304176031], [-0.1234091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xval_rl</th>\n",
       "      <td>[[0.314502619466, -0.134699458319, 0.043601035...</td>\n",
       "      <td>[[0.464711356861, 0.779820082528, -0.538093560...</td>\n",
       "      <td>[[-1.17785941539, 0.441021282575, 0.8544769675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ytr_rl</th>\n",
       "      <td>[[1], [1], [0], [0], [0], [0], [0], [0], [1], ...</td>\n",
       "      <td>[[1], [0], [0], [0], [0], [1], [0], [0], [1], ...</td>\n",
       "      <td>[[1], [0], [0], [0], [0], [0], [0], [0], [1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yval_rl</th>\n",
       "      <td>[[0], [0], [1], [1], [0], [1], [1], [0], [1], ...</td>\n",
       "      <td>[[1], [0], [0], [1], [0], [0], [1], [1], [0], ...</td>\n",
       "      <td>[[0], [0], [1], [0], [0], [0], [1], [1], [1], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  100276687  \\\n",
       "k_knn                                                 [[5]]   \n",
       "str_reg   [[-1.81730391168], [-1.31959494449], [-3.12276...   \n",
       "sval_reg  [[0.469566566998], [0.434864239432], [-0.20126...   \n",
       "xtr_reg   [[0.871257484747, -0.820094192472], [-0.644532...   \n",
       "xtr_rl    [[0.140463102615, 0.247669377199, -0.041431362...   \n",
       "xval_reg  [[-0.0087916089067, -2.38238053595], [-0.42707...   \n",
       "xval_rl   [[0.314502619466, -0.134699458319, 0.043601035...   \n",
       "ytr_rl    [[1], [1], [0], [0], [0], [0], [0], [0], [1], ...   \n",
       "yval_rl   [[0], [0], [1], [1], [0], [1], [1], [0], [1], ...   \n",
       "\n",
       "                                                  100284423  \\\n",
       "k_knn                                                 [[6]]   \n",
       "str_reg   [[-1.95300967366], [-0.219953516073], [0.77476...   \n",
       "sval_reg  [[-1.69798029129], [-0.998549158711], [-7.1524...   \n",
       "xtr_reg   [[0.306152918607, 0.399930040105], [0.38405830...   \n",
       "xtr_rl    [[-0.147325230568, 0.954388079256, -0.27748399...   \n",
       "xval_reg  [[1.18442826324, -0.100688112884], [1.07725826...   \n",
       "xval_rl   [[0.464711356861, 0.779820082528, -0.538093560...   \n",
       "ytr_rl    [[1], [0], [0], [0], [0], [1], [0], [0], [1], ...   \n",
       "yval_rl   [[1], [0], [0], [1], [0], [0], [1], [1], [0], ...   \n",
       "\n",
       "                                                  100290949  \n",
       "k_knn                                                 [[7]]  \n",
       "str_reg   [[-6.78524715177], [-0.167566954327], [-0.5772...  \n",
       "sval_reg  [[5.21761697592], [1.21333038463], [-2.5538643...  \n",
       "xtr_reg   [[-1.33671463676, -2.14137382412], [0.24677755...  \n",
       "xtr_rl    [[0.524746496819, 0.296185529951, 0.7269493561...  \n",
       "xval_reg  [[-0.046398183217, 1.46304176031], [-0.1234091...  \n",
       "xval_rl   [[-1.17785941539, 0.441021282575, 0.8544769675...  \n",
       "ytr_rl    [[1], [0], [0], [0], [0], [0], [0], [0], [1], ...  \n",
       "yval_rl   [[0], [0], [1], [0], [0], [0], [1], [1], [1], ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "datafiles_path = '../GenerateData/'\n",
    "##########################################\n",
    "\n",
    "student_data = readdatafiles(datafiles_path, splitsymbol='_')\n",
    "\n",
    "print 'Number of students in dataframe: ' + str(student_data.shape[1])\n",
    "print 'Number of variables read: ' + str(student_data.shape[0])\n",
    "\n",
    "print 'Displaying data for first three students ... '\n",
    "student_data[student_data.columns[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read answers provided by students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Read student results into panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "results_path = '../Entregas/'\n",
    "#Requested variable names in the wording of the exam\n",
    "truenames = ['s0', 'E2val', 's_prom', 'E2val_knn', 'w_mean', 'w_cov',\n",
    "            'mx','sx','xn_tr','xn_val','w10', 'rho', 'lg10', 'n1', 'emin', 'nvar', 'wmin']\n",
    "###########################################\n",
    "\n",
    "student_results = readdatafiles(results_path, splitsymbol='_')\n",
    "newindex = truenames+[el for el in student_results.index.tolist() if el not in truenames]\n",
    "student_results = student_results.reindex(newindex)\n",
    "\n",
    "print 'Number of students in dataframe: ' + str(student_results.shape[1])\n",
    "print 'Number of variables read: ' + str(student_results.shape[0])\n",
    "\n",
    "print 'Displaying data for first three students ... '\n",
    "student_results[student_results.columns[:13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Common Mistakes on variable names\n",
    "\n",
    "In view of all variable names provided by all students, we may decide to allow alternative names for variables without any penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in dataframe: 54\n",
      "\n",
      "Displaying number of missing data per variable name. \n",
      "Those with a large number are a potential common mistake\n",
      "for a variable name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s0            6\n",
       "E2val         6\n",
       "s_prom        4\n",
       "E2val_knn     6\n",
       "w_mean       18\n",
       "w_cov        18\n",
       "mx            4\n",
       "sx            4\n",
       "xn_tr         4\n",
       "xn_val        8\n",
       "w10          15\n",
       "rho          20\n",
       "lg10         20\n",
       "n1           27\n",
       "emin         35\n",
       "nvar         37\n",
       "wmin         35\n",
       "k_knn        40\n",
       "n0           53\n",
       "s            53\n",
       "str_reg      40\n",
       "sval_reg     40\n",
       "xn_va        53\n",
       "xtr_reg      40\n",
       "xtr_rl       40\n",
       "xval_reg     40\n",
       "xval_rl      40\n",
       "ytr_rl       40\n",
       "yval_rl      40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Number of students in dataframe: ' + str(student_results.shape[1])\n",
    "\n",
    "print '\\nDisplaying number of missing data per variable name. \\nThose with a large number are a potential common mistake\\nfor a variable name'\n",
    "\n",
    "student_results.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "\n",
    "#Dictionary with accepted mistakes in the following format\n",
    "#  Expected variable name : Accepted mistake\n",
    "Mistakes = {'xn_val': 'xn_va'};\n",
    "##########################################\n",
    "\n",
    "for el in Mistakes:\n",
    "    student_results.loc[el] = student_results.loc[el].fillna(student_results.loc[Mistakes[el]])\n",
    "    \n",
    "for el in student_results.index.tolist():\n",
    "    if el not in truenames:\n",
    "        student_results.drop(el, inplace=True)\n",
    "        \n",
    "student_results[student_results.columns[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Name to NIA dictionary\n",
    "\n",
    "Finally, since datafiles are created by NIA and results are available per student name, we need to create a dictionary connecting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "excel_file = 'ListaClase.xlsx'\n",
    "language = 'spanish'\n",
    "###########################################\n",
    "\n",
    "student_NIA_names = pd.read_excel(excel_file)\n",
    "\n",
    "#UTF-8 encoding of everything\n",
    "for fld in student_NIA_names.keys():\n",
    "    if fld != 'NIU':\n",
    "        student_NIA_names[fld] = student_NIA_names[fld].str.encode('utf8')\n",
    "\n",
    "NIA_name = {}\n",
    "\n",
    "for el in student_results.columns.tolist():\n",
    "\n",
    "    sim_list = []\n",
    "\n",
    "    for idx,NIA in enumerate(student_NIA_names['NIU'].values):\n",
    "    \n",
    "        if language=='english':\n",
    "            std_name = student_NIA_names['First name'].values.tolist()[idx] + ' ' + \\\n",
    "                            student_NIA_names['Surname'].values.tolist()[idx]\n",
    "            sim_list.append(difflib.SequenceMatcher(a=el.lower(), b=std_name.lower()).ratio())\n",
    "        else:\n",
    "            std_name = student_NIA_names['Nombre'].values.tolist()[idx] + ' ' + \\\n",
    "                            student_NIA_names['Apellido(s)'].values.tolist()[idx]\n",
    "            sim_list.append(difflib.SequenceMatcher(a=el.lower(), b=std_name.lower()).ratio())\n",
    "    \n",
    "    max_sim = max(sim_list)\n",
    "    max_idx = sim_list.index(max_sim)\n",
    "    \n",
    "    NIA_name[student_NIA_names['NIU'].values.tolist()[max_idx]] = el\n",
    "\n",
    "#Create dictionary for students that did not hand in anything\n",
    "NIA_name_nodata = {}\n",
    "lista1 = [el for el in student_NIA_names['NIU'].values if el not in NIA_name.keys()]\n",
    "lista2 = [student_NIA_names[student_NIA_names['NIU']==NIA]['Nombre'].values.tolist()[0] + ' ' + \\\n",
    "          student_NIA_names[student_NIA_names['NIU']==NIA]['Apellido(s)'].values.tolist()[0] for NIA in lista1]   \n",
    "for el in zip(lista1,lista2):\n",
    "    NIA_name_nodata[el[0]] = el[1]\n",
    "    \n",
    "#Create name to NIA dictionary\n",
    "name_NIA = {NIA_name[el]: el for el in NIA_name}\n",
    "name_NIA_nodata = {NIA_name_nodata[el]: el for el in NIA_name_nodata}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print name_NIA\n",
    "#print NIA_name\n",
    "for el in NIA_name.keys():\n",
    "    print str(el) + ' : ' + NIA_name[el]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have:\n",
    "\n",
    "   * student_data: dataframe with data given to the students. Each index is a variable, and each column a NIA\n",
    "   * student_results: dataframe with student results. Each index is a variable, and each column a name\n",
    "   * NIA_name: NIA to name dictionary\n",
    "   * name_NIA: name to NIA dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Exam solution\n",
    "\n",
    "In this section we implement the solution to the exam. This is a function that takes the variables generated for a given student and the answers provided by the student, and generates a structure with all posible answers, possibly with a penalty term associated to each answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print NIA_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Busqueda por nombre\n",
    "student = \n",
    "#student = \n",
    "print student_data[str(name_NIA[student])]\n",
    "print \" \"\n",
    "print student_results[student.decode('utf8')]\n",
    "##Busqueda por NIA\n",
    "#NIA = '100339092'\n",
    "#print student_data[NIA]\n",
    "#print \" \"\n",
    "#print student_results[NIA_name[int(NIA)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Some methods required for the Classification solution\n",
    "def normalize(X, mx=None, sx=None):\n",
    "\n",
    "    # Compute means and standard deviations\n",
    "    if mx is None:\n",
    "        mx = np.mean(X, axis=0)\n",
    "    if sx is None:\n",
    "        sx = np.std(X, axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    X0 = (X-mx)/sx\n",
    "\n",
    "    return X0, mx, sx\n",
    "\n",
    "# Define the logistic function\n",
    "def logistic(x):\n",
    "    p = 1.0 / (1 + np.exp(-x))\n",
    "    return p\n",
    "\n",
    "# MAP trainer.\n",
    "def logregFitR(Z_tr, Y_tr, rho, C, n_it):\n",
    "\n",
    "    # Initialize variables\n",
    "    n_dim = Z_tr.shape[1]\n",
    "    nll_tr = np.zeros(n_it)\n",
    "    w = 0*np.random.randn(n_dim, 1)\n",
    "\n",
    "    # Running the gradient descent algorithm\n",
    "    for n in range(n_it):\n",
    "\n",
    "        # Compute posterior probabilities for weight w\n",
    "        p1_tr = logistic(np.dot(Z_tr, w))\n",
    "        p0_tr = logistic(-np.dot(Z_tr, w))\n",
    "        # Compute negative log-likelihood\n",
    "        nll_tr[n] = (- np.dot(Y_tr.T, np.log(p1_tr)) - np.dot((1-Y_tr).T, np.log(p0_tr)))\n",
    "        # Update weights\n",
    "        w = (1-2*rho/C)*w + rho*np.dot(Z_tr.T, Y_tr - p1_tr)\n",
    "\n",
    "    return w, nll_tr\n",
    "\n",
    "# MAP trainer.\n",
    "def computeNLL(Z, Y, w):\n",
    "\n",
    "    # Compute posterior probabilities for weight w\n",
    "    p1 = logistic(np.dot(Z, w))\n",
    "    p0 = logistic(-np.dot(Z, w))\n",
    "    # Compute negative log-likelihood\n",
    "    nll = (- np.dot(Y.T, np.log(p1)) - np.dot((1-Y).T, np.log(p0)))\n",
    "\n",
    "    return nll\n",
    "\n",
    "# Compute predictions for a given model\n",
    "def logregPredict(Z, w):\n",
    "\n",
    "    # Compute posterior probability of class 1 for weights w.\n",
    "    p = logistic(np.dot(Z, w))\n",
    "    # Classify\n",
    "    D = [int(round(pn)) for pn in p]\n",
    "\n",
    "    return p, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def isVarFail(x):\n",
    "    \n",
    "    # Check if the variable contains all None.\n",
    "    try:\n",
    "        return np.all(np.isnan(x))\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def SolveClassif(Xtrain, Xval, xval_rl, ytr_rl, yval_rl, rho_, wst=None):\n",
    "\n",
    "    ## Sec. 3c\n",
    "    # Set parameters\n",
    "    C = 100\n",
    "    n_it = 100\n",
    "\n",
    "    # Compute extended vector\n",
    "    n_tr = Xtrain.shape[0]\n",
    "    Z_tr = np.concatenate((np.ones((n_tr, 1)), Xtrain), axis=1)\n",
    "    if wst is None:\n",
    "        w10_, nll = logregFitR(Z_tr, ytr_rl, rho_, C, n_it)\n",
    "    else:\n",
    "        w10_ = wst\n",
    "\n",
    "    # This variable is requested, but actually not used for evaluation.\n",
    "    rho = [(np.array(rho_), 1)]\n",
    "\n",
    "    ## Sec. 3d Compute NLL\n",
    "    n_val = Xval.shape[0]\n",
    "    Z_val = np.concatenate((np.ones((n_val, 1)), Xval), axis=1)\n",
    "    lg10a = computeNLL(Z_val, yval_rl, w10_)\n",
    "\n",
    "    ## Sec. 3e              \n",
    "    p1, D1 = logregPredict(Z_val, w10_)\n",
    "    n1a = np.sum(np.array(D1) == 1)\n",
    "\n",
    "    # The following alternative response is incorrect, \n",
    "    # but the students are certainly induced to do it in the statement...\n",
    "    if np.array_equal(Xval.shape, xval_rl.shape):\n",
    "        Z_valb = np.concatenate((np.ones((n_val, 1)), xval_rl), axis=1)\n",
    "        lg10b = computeNLL(Z_valb, yval_rl, w10_)\n",
    "        p1b, D1b = logregPredict(Z_valb, w10_)\n",
    "        n1b = np.sum(np.array(D1b) == 1)\n",
    "    else:\n",
    "        lg10b = lg10a\n",
    "        n1b = n1a\n",
    "\n",
    "    ## Sec. 3f.\n",
    "    # Removing single variables\n",
    "    emin_ = 10000*n_val\n",
    "    for i in range(10):\n",
    "\n",
    "        Ztr_i = np.delete(Z_tr, i+1, 1)\n",
    "        Zval_i = np.delete(Z_val, i+1, 1)\n",
    "\n",
    "        wi, nll = logregFitR(Ztr_i, ytr_rl, rho_, C, n_it)\n",
    "        p1, D1 = logregPredict(Zval_i, wi)\n",
    "\n",
    "        ei = np.mean(np.array(D1)[:,np.newaxis] != yval_rl)\n",
    "\n",
    "        if ei <= emin_:\n",
    "            emin_ = ei\n",
    "            nvara = i + 1\n",
    "            nvarb = i     # This is not correct, but I accept it because the statement is not much clear about this.\n",
    "            wmin_ = wi\n",
    "\n",
    "    return w10_, lg10a, lg10b, n1a, n1b, emin_, nvara, nvarb, wmin_\n",
    "    \n",
    "def SolveLabXX(data, st_solution):\n",
    "    \"\"\"Solver for the practical\n",
    "    Input parameters:\n",
    "    data: A series with the data given to the student\n",
    "    st_solution: The solution provided by the student\n",
    "    \n",
    "    Output: A dataseries where each element is a list of tuples\n",
    "    with the format [(solution1, factor1), (solution2, factor2)]\n",
    "    \n",
    "    Factors are multiplicative factors to account for possible\n",
    "    penalties. A factor 1 should be given to a solution that should\n",
    "    not be penalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    ds_values = []\n",
    "    ds_indexes = []\n",
    "    \n",
    "    # #############\n",
    "    # ## REGRESSION\n",
    "\n",
    "    ## Sec. 2.1\n",
    "    s0 = []\n",
    "    \n",
    "    s0.append((np.mean(data['str_reg']),1))\n",
    "    \n",
    "    ds_values.append(s0)\n",
    "    ds_indexes.append('s0')\n",
    "    \n",
    "    E2val = []\n",
    "    \n",
    "    \n",
    "    E2val.append((np.mean((data['sval_reg'] - s0[0][0])**2),1))\n",
    "    #Penalizamos al 50% si hicieron el total, en lugar del promedio\n",
    "    E2val.append((np.sum((data['sval_reg'] - s0[0][0])**2),.5))\n",
    "    \n",
    "    #Usando el valor de s0 proporcionado por el alumno\n",
    "    st_s0 = np.array(st_solution['s0']).flatten()[0]\n",
    "    if not np.all(np.isnan(st_s0)):\n",
    "        E2val.append((np.mean((data['sval_reg'] - st_s0)**2),.7))\n",
    "        E2val.append((np.sum((data['sval_reg'] - st_s0)**2),.35))\n",
    "    \n",
    "    ds_values.append(E2val)\n",
    "    ds_indexes.append('E2val')\n",
    "\n",
    "    ## Sec. 2.2\n",
    "    s_prom = []\n",
    "    E2val_knn = []\n",
    "\n",
    "    knn = neighbors.KNeighborsRegressor(data['k_knn'][0,0], weights='uniform')\n",
    "    sval = knn.fit(data['xtr_reg'], data['str_reg']).predict(data['xval_reg'])\n",
    "    s_prom.append((np.mean(sval), 1))\n",
    "    E2val_knn.append((np.mean((data['sval_reg'] - sval)**2),1))\n",
    "    knn = neighbors.KNeighborsRegressor(data['k_knn'][0,0], weights='distance')\n",
    "    sval = knn.fit(data['xtr_reg'], data['str_reg']).predict(data['xval_reg'])\n",
    "    s_prom.append((np.mean(sval), 1))\n",
    "    E2val_knn.append((np.mean((data['sval_reg'] - sval)**2),1))\n",
    "\n",
    "    #Si se calcula sobre los datos de train x0.5\n",
    "    knn = neighbors.KNeighborsRegressor(data['k_knn'][0,0], weights='uniform')\n",
    "    sval = knn.fit(data['xtr_reg'], data['str_reg']).predict(data['xtr_reg'])\n",
    "    s_prom.append((np.mean(sval), 1))\n",
    "    E2val_knn.append((np.mean((data['str_reg'] - sval)**2),.5))\n",
    "    knn = neighbors.KNeighborsRegressor(data['k_knn'][0,0], weights='distance')\n",
    "    sval = knn.fit(data['xtr_reg'], data['str_reg']).predict(data['xtr_reg'])\n",
    "    s_prom.append((np.mean(sval), 1))\n",
    "    E2val_knn.append((np.mean((data['str_reg'] - sval)**2),.5))\n",
    "    \n",
    "    ds_values.append(s_prom)\n",
    "    ds_indexes.append('s_prom')\n",
    "    ds_values.append(E2val_knn)\n",
    "    ds_indexes.append('E2val_knn')\n",
    "\n",
    "    ## Sec. 2.3\n",
    "    Z = np.hstack((np.ones((500,1)),data['xtr_reg'],np.exp(data['xtr_reg'])))\n",
    "\n",
    "    Sigma_p = 2*np.eye(5)\n",
    "    var_n = .5\n",
    "\n",
    "    w_cov = []\n",
    "    w_cov.append((np.linalg.inv(Z.T.dot(Z)/var_n + np.linalg.inv(Sigma_p)),1))\n",
    "\n",
    "    ds_values.append(w_cov)\n",
    "    ds_indexes.append('w_cov')\n",
    "\n",
    "    w_mean = []\n",
    "    w_mean.append((w_cov[0][0].dot(Z.T).dot(data['str_reg'])/var_n,1))\n",
    "\n",
    "    ds_values.append(w_mean)\n",
    "    ds_indexes.append('w_mean')\n",
    "\n",
    "    # #################\n",
    "    # ## CLASSIFICATION\n",
    "\n",
    "    ## Standard correct response:\n",
    "\n",
    "    ## Sec. 3a\n",
    "    # Get data\n",
    "    xtr_rl = data['xtr_rl']\n",
    "    xval_rl = data['xval_rl']\n",
    "    ytr_rl = data['ytr_rl']\n",
    "    yval_rl = data['yval_rl']\n",
    "\n",
    "    # Compute mean and std and normalize\n",
    "    Xtrain, mx0, sx0 = normalize(xtr_rl)\n",
    "    Xval, mx0, sx0 = normalize(xval_rl, mx0, sx0)\n",
    "\n",
    "    # Save means and variances\n",
    "    mx = [(mx0, 1)]\n",
    "    sx = [(sx0**2, 1), (sx0, 0.9)]   # The 2n response is incorrect, but the statement induces to compute it.\n",
    "\n",
    "    ## Sec. 3b\n",
    "    # Normalized variables have been computed in the previous section\n",
    "    xn_tr = [(Xtrain, 1)]\n",
    "    xn_val = [(Xval, 1)]\n",
    "\n",
    "    # Solve the rest of the questions\n",
    "    rho_ = 0.001\n",
    "    w10_, lg10a, lg10b, n1a, n1b, emin_, nvara, nvarb, wmin_ = SolveClassif(\n",
    "        Xtrain, Xval, xval_rl, ytr_rl, yval_rl, rho_)\n",
    "    w10 = [(w10_, 1)]\n",
    "    rho = [(np.array(rho_), 1)]   # This variable is requested, but not used for evaluation\n",
    "    lg10 = [(lg10a, 1), (lg10b, 0.9)]\n",
    "    n1 = [(n1a, 1), (n1b, 0.9)]\n",
    "    emin = [(emin_, 1)]\n",
    "    nvar = [(nvara, 1), (nvarb, 1)]\n",
    "    wmin = [(wmin_, 1)]\n",
    "\n",
    "    ## ALTERNATIVE 1: USING A DIFFERENT rho: \n",
    "    # Set parameters\n",
    "    rho_2 = rho_\n",
    "    if not np.all(np.isnan(st_solution['rho'])):\n",
    "        if np.array(st_solution['rho']).flatten().shape[0] == 1:\n",
    "            rho_2 = st_solution['rho']\n",
    "\n",
    "            w10_2, lg10a2, lg10b2, n1a2, n1b2, emin_2, nvar_2a, nvar_2b, wmin_2 = SolveClassif(\n",
    "                Xtrain, Xval, xval_rl, ytr_rl, yval_rl, rho_2)\n",
    "            if rho_2 > 0:\n",
    "                w10 = [(w10_, 0.8), (w10_2, 1)]    # I modify the score for w10_ because of claiming a different rho.\n",
    "                lg10 += [(lg10a2, 1), (lg10b2, 0.9)]\n",
    "                n1 += [(n1a2, 1), (n1b2, 0.9)]\n",
    "                emin += [(emin_2, 1)]\n",
    "                nvar += [(nvar_2a, 1), (nvar_2b, 1)]\n",
    "                wmin += [(wmin_2, 1)]\n",
    "            else:\n",
    "                w10 = [(w10_, 0.8), (w10_2, 0.1)]   # I modify the score for w10_ because of claiming a different rho.\n",
    "                lg10 += [(lg10a2, 1), (lg10b2, 0.9)]\n",
    "                n1 += [(n1a2, 1), (n1b2, 0.9)]\n",
    "                emin += [(emin_2, 0.1)]\n",
    "                nvar += [(nvar_2a, 0.1), (nvar_2b, 0.1)]\n",
    "                wmin += [(wmin_2, 0.1)]\n",
    "\n",
    "    ## ALTERNATIVE 2: USING STUDENT'S TRAINING DATA MATRIX\n",
    "    # From now on, I use the declared rho\n",
    "    if not isVarFail(st_solution['xn_tr']):\n",
    "        Xtrain2 = st_solution['xn_tr']\n",
    "        if np.array_equal(Xtrain.shape, Xtrain2.shape):\n",
    "            w10_3, lg10a3, lg10b3, n1a3, n1b3, emin_3, nvar_3a, nvar_3b, wmin_3 = SolveClassif(\n",
    "                Xtrain2, Xval, xval_rl, ytr_rl, yval_rl, rho_2)\n",
    "\n",
    "            if rho_2 > 0:\n",
    "                w10 += [(w10_3, 1)]    \n",
    "                lg10 += [(lg10a3, 1), (lg10b3, 0.9)]\n",
    "                n1 += [(n1a3, 1), (n1b3, 0.9)]\n",
    "                emin += [(emin_3, 1)]\n",
    "                nvar += [(nvar_3a, 1), (nvar_3b, 1)]\n",
    "                wmin += [(wmin_3, 1)]\n",
    "            else:\n",
    "                w10 += [(w10_3, 0.1)]\n",
    "                lg10 += [(lg10a3, 1), (lg10b3, 0.9)]\n",
    "                n1 += [(n1a3, 1), (n1b3, 0.9)]\n",
    "                emin += [(emin_3, 0.1)]\n",
    "                nvar += [(nvar_3a, 0.1), (nvar_3b, 0,1)]\n",
    "                wmin += [(wmin_3, 0.1)]\n",
    "\n",
    "    ## ALTERNATIVE 2: USING STUDENT'S WEIGHTS\n",
    "    w10st = np.array(st_solution['w10'])\n",
    "    if not isVarFail(w10st):\n",
    "        if np.array_equal(w10_.shape, w10st.shape):\n",
    "            w10_4, lg10a4, lg10b4, n1a4, n1b4, emin_4, nvar_4a, nvar_4b, wmin_4 = SolveClassif(\n",
    "                Xtrain, Xval, xval_rl, ytr_rl, yval_rl, rho_2, w10st)\n",
    "            lg10 += [(lg10a4, 0.9), (lg10b4, 0.8)]\n",
    "            n1 += [(n1a4, 0.9), (n1b4, 0.8)]\n",
    "\n",
    "    ## ALTERNATIVE 3: USING STUDENT'S WEIGHTS AND DATA VALIDATION MATRIX\n",
    "    # Now the same, but using the student weights and data matrix\n",
    "    if not isVarFail(w10st) and not isVarFail(st_solution['xn_val']):\n",
    "        Xval2 = st_solution['xn_val']\n",
    "        if np.array_equal(Xval.shape, Xval2.shape) and np.array_equal(w10_.shape, w10st.shape):\n",
    "            w10_5, lg10a5, lg10b5, n1a5, n1b5, emin_5, nvar_5a, nvar_5b, wmin_5 = SolveClassif(\n",
    "                Xtrain, Xval2, xval_rl, ytr_rl, yval_rl, rho_2, w10st)\n",
    "            lg10 += [(lg10a5, 0.9), (lg10b5, 0.8)]\n",
    "            n1 += [(n1a5, 0.9), (n1b5, 0.8)]\n",
    "\n",
    "    ds_indexes.append('mx')\n",
    "    ds_values.append(mx)\n",
    "    ds_indexes.append('sx')\n",
    "    ds_values.append(sx)\n",
    "    ds_indexes.append('xn_tr')\n",
    "    ds_values.append(xn_tr)\n",
    "    ds_indexes.append('xn_val')\n",
    "    ds_values.append(xn_val)\n",
    "    ds_indexes.append('w10')\n",
    "    ds_values.append(w10)\n",
    "    ds_indexes.append('rho')\n",
    "    ds_values.append(rho)\n",
    "    ds_indexes.append('lg10')\n",
    "    ds_values.append(lg10)    \n",
    "    ds_indexes.append('n1')\n",
    "    ds_values.append(n1)\n",
    "    ds_indexes.append('emin')\n",
    "    ds_values.append(emin)\n",
    "    ds_indexes.append('nvar')\n",
    "    ds_values.append(nvar)\n",
    "    ds_indexes.append('wmin')\n",
    "    ds_values.append(wmin)\n",
    "    \n",
    "    return pd.Series(ds_values, ds_indexes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print student_results[student]\n",
    "print \" \"\n",
    "print SolveLabXX(student_data[str(name_NIA[student])], student_results[student])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation of all students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def automatic_evaluator(NIA, student_results, solution, weights, tolerance):\n",
    "    \n",
    "    val=[]\n",
    "    idx=[]\n",
    "    \n",
    "    if len(solution.keys())==len(weights) and len(solution.keys())==len(tolerance):\n",
    "\n",
    "        for wgh, el, tol in zip(weights,solution.keys(),tolerance):\n",
    "\n",
    "            var_summary = []\n",
    "            #If the student has delivered the variable, append 1; otherwise 0\n",
    "            try:\n",
    "                isAllNaN = np.all(np.isnan(student_results[el]))\n",
    "            except:\n",
    "                isAllNaN = True\n",
    "                \n",
    "            if not isAllNaN:    # np.all(np.isnan(student_results[el])):\n",
    "                var_summary.append(1)\n",
    "                #Check all possible solutions against the one provided by the student\n",
    "                factors = [entry[1] for entry in solution[el]\n",
    "                           if np.array_equal(np.array(student_results[el]).flatten().shape,\n",
    "                                             np.array(entry[0]).flatten().shape) and\n",
    "                              np.mean(np.abs(np.array(entry[0]).flatten() - \n",
    "                                      np.array(student_results[el]).flatten())) < tol]\n",
    "                print el\n",
    "                print [np.mean(np.abs(np.array(entry[0]).flatten() - \n",
    "                                      np.array(student_results[el]).flatten())) for entry in solution[el]]\n",
    "                print factors\n",
    "                \n",
    "                if len(factors):\n",
    "                    max_factor = max(factors)\n",
    "                    var_summary.extend([max_factor, wgh, max_factor*wgh])\n",
    "                else:\n",
    "                    var_summary.extend([0, wgh, 0])\n",
    "            else:\n",
    "                var_summary.extend([0, 0, wgh, 0])\n",
    "\n",
    "            # Keep values corresponding to current variable\n",
    "            val.append(var_summary)\n",
    "            idx.append(el)\n",
    "            \n",
    "        final_score = sum([item[-1] for item in val])\n",
    "        val.append(final_score)\n",
    "        idx.append('FinalScore')\n",
    "        \n",
    "    else:\n",
    "        print 'The number of weights and variables to evaluate differ. Please, check'\n",
    "    \n",
    "    val.append(NIA)\n",
    "    idx.append('NIA')\n",
    "    return pd.Series(val,index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# EXAM DEPENDENT VARIABLE\n",
    "excel_output = 'Notas_MIT.xlsx'\n",
    "all_students = 1 #Include in the list students that did not carry out the exam\n",
    "weightsR = [.5, .5, 1, 1, 1, 1]\n",
    "weightsC = [.5, .5, .5, .5, 1, 0, 1, 1, 1.0/3, 1.0/3, 1.0/3]\n",
    "sR = sum(weightsR)\n",
    "sC = sum(weightsC)\n",
    "weights = [w*6.0/sR for w in weightsR] + [w*4.0/sC for w in weightsC]\n",
    "print weights\n",
    "\n",
    "tolerance = [1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 5e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2, 1e-2]\n",
    "###########################################\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "print len(NIA_name.keys())\n",
    "\n",
    "for NIA in NIA_name.keys():\n",
    "    print NIA_name[NIA]\n",
    "    solution = SolveLabXX(student_data[str(NIA)], student_results[NIA_name[NIA]])\n",
    "    df[NIA_name[NIA].decode('utf8')] = automatic_evaluator(NIA, student_results[NIA_name[NIA]], solution, weights, \n",
    "                                                           tolerance)\n",
    "print df\n",
    "\n",
    "if all_students:\n",
    "    for NIA in NIA_name_nodata.keys():\n",
    "        df[NIA_name_nodata[NIA].decode('utf8')] = pd.Series([NIA],index=['NIA'])\n",
    "        \n",
    "df.T.to_excel(excel_output,columns=df.T.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
